[<< back to main index](../README.md)

Lab 4.5: MyFlix
===============

### Overview
Apply all modeling exercises, experiment with data

* Design myflix tables
* populate the tables with data

Note: Phoenix installed on our Hadoop cluster. For this lab, we recommend using it. However, you can continue
working with your Phoenix install that you have created in Lab 4.1

### Builds on
None

### Run time
approx. 20 minutes

### Working directory
`hadoop-adv-labs/4-hbase/`


## STEP 1: Connect to Phoenix     
    
To start the Phoenix shell, called `sqlline`

     
```bash
    $  ~/phoenix/bin/sqlline.py   <internal-ip-of-zookeeper>:2181:/hbase-unsecure
```
     
For example, your command may like as follows
```bash 
     $   ~/phoenix/bin/sqlline.py    localhost:2181:/hbase-unsecure
     # or 
     $   ~/phoenix/bin/sqlline.py    ip-10-16-184-103.ec2.internal:2181:/hbase-unsecure
```

## STEP 2: USERS

Provided that you create, or have already created a table as follows (notice the use of your name)
    
```
  phoenix> 
            CREATE TABLE <your-name>_users (
               user_name VARCHAR NOT NULL PRIMARY KEY,
               fname VARCHAR,
               lname VARCHAR,
               emails VARCHAR ARRAY   
            );
```

To generate the data, run the following command in the `4-hbase/generators` folder in the lab
```bash    
    $   python generators/generate-users.py
```
    
To load the data, exit `sqlline`, then do the following command
    
```
    $   ~/phoenix/bin/psql.py -t <your-name>_users  zk1,zk2,zk3:/hbase-unsecure  users.csv
```
    
Your real-life command may look more like this
    
```
    $   ~/phoenix/bin/psql.py   -t   MYNAME_USERS   localhost:/hbase-unsecure users.csv
```

Note: table name for Phoenix import should be all upper case. `sqlline` is permissive, by `psql' is not.    
    


## STEP 3: FEATURES

#### Create table (if not already created)

```
    phoenix>
            CREATE TABLE <your-name>_features (
              code  VARCHAR NOT NULL PRIMARY KEY,
              name VARCHAR,
              studio VARCHAR,
              release_date TIMESTAMP,
              type VARCHAR
            );
```

#### Populate features table with data

* We are going to generate `features` data.
* Script to use :  `generators/generate-features.py`
* Edit script `generators/generate-features.py`  and update the following line
```
table = 'MYNAME_features'
```

Run the script to generate data
```bash
      $  python  generators/generate-features.py
```

This will generate  'features.sql' file.  
This file contains SQL statements to populate features table.  
Inspect the file.
```bash
    $ less features.sql

    # use 'q' to exit less viewer
```


Import the features.data
```bash
      $   ~/phoenix/bin/psql.py   -t   <your-name>_features    zk1,zk2,zk3:/hbase-unsecure features.sql
```

Your real-life command may look more like this.  
**Make sure table names are in CAPS like MYNAME_FEATURES**  
```bash
      $   ~/phoenix/bin/psql.py    -t   MYNAME_FEATURES   localhost:/hbase-unsecure    features.sql
```


##  STEP 4 : Create indexes for features table

We want to find all features by a particular studio, say 'HBO'
Try this query:
```
    phoenix>    
          select *  from MYNAME_features where studio = 'HBO';
```

We can add an index.
```
    phoenix>    
            create index name_of_index  on table(column_name)
```

Now do the same query again.

Also add an index on 'type' column.  
Query for all features of `type=Movie and studio=HBO`   
What is the result of query execution?  why?  


## STEP 5: Ratings table

Create 'ratings_by_user' table with following attributes
- user_name : varchar
- feature_code : varchar
- rating : integer  // 1 -- 5
- primary key (???,  ???)

Also create 'ratings_by_feature' table
- what are the attributes?
- and primary key?

use `generators/generate-ratings.py`  to generate some ratings data and import it into the table.  
Follow similar procedure as in previous steps


## STEP 6: Populating  'ratings_by_feature' table

In step-5 the `generators/generate-ratings.py` script only populated `ratings_by_user` table.  
Modify the script to add data for `ratings_by_feature`   table.   
Hint : look around line 31 in the python script

After updating the script, run it again and import the data.  
Hint : you may want to clear the data that is already in table `ratings_by_user` before re-importing

## STEP 7: Queries

Q1 : select * from ratings_by_feature;
    what is the order of data?

Q2 : select * from ratings_by_user;
    what is the order order of data?

Q3 : Find all ratings by a particular user

Q4 : Find all ratings by a feature / movie

Q5 : Find the best / worst rating for a movie


## STEP 8: Use hbase shell to inspect the data

```
    $  hbase shell

    hbase>
            scan ratings_by_user;
            scan list ratings_by_features;
```

Q : how is HBase storing the data?


## BONUS Lab 1:  rating distribution
for each movie, find out how ratings are distributed.
    e.g.      rating 1 : given by 10 users
              rating 2 : given by 20 users
              ..etc
interesting reads:
    - https://www.cs.duke.edu/courses/spring09/cps296.3/lectures/12-colfil-multiscale.pdf


## BONUS Lab 2: global rating distribution
Find out how many movies have a particular rating
e.g.        70 movies have rating 1
           100 movies have rating 2
           ...etc